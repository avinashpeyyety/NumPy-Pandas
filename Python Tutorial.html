<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Python Tutorial - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableSshKeyUI":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","workspaceFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/databricks_guide/index.html","displayName":"Databricks Guide","icon":"question"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/sample_applications/index.html","displayName":"Application Examples","icon":"code"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/courses/index.html","displayName":"Training","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","maxCustomTags":45,"enableInstanceProfilesUIInJobs":false,"nodeInfo":{"node_types":[{"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"memory_mb":6144,"category":"Community Edition","num_cores":0.88,"support_ebs_volumes":false}],"default_node_type_id":"dev-tier-node"},"enableThirdPartyApplicationsUI":false,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"enableTableHandler":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"enableLargeResultDownload":true,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableMaxConcurrentRuns":false,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"clusters":true,"allowRunOnPendingClusters":true,"applications":false,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"sparkVersions":[{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-35f30dcf90b59210c3f253a98dbb4d255fa4a1773385163b3cec143c1271e065","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-876320751f9b6e4318a1235c9d5f862196d02008ff478f483e2820c48c59d1fe","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":false,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"class-node":1,"r3.8xlarge":8,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":8,"memory-optimized":1,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"c3.4xlarge":2,"g2.2xlarge":2,"c4.8xlarge":4,"r3.xlarge":1,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"sanitizeMarkdownHtml":true,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":false,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.31","accountsLimit":3,"enableX509Authentication":false,"enableNotebookGitBranching":true,"local":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"disableLegacyDashboards":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":4096,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"defaultSparkVersion":{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":true,"enableMountAclsConfig":false,"useDevTierHomePage":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableClusterAclsByTier":false,"disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","enableOrgSwitcherUI":true,"clustersLimit":1,"enableJdbcImport":true,"logfiles":"logfiles/","enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"useFixedStaticNotebookVersionForDevelopment":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableDashboardViews":false,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableWorkspaceAclService":true,"docsDomain":"https://docs.cloud.databricks.com/","enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"d021cfb95994095f8eba80e12423a5f1461121b6","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":true,"enableDebugUI":false,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSparkPackages":true,"dynamicSparkVersions":true,"enableNotebookHistoryUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"enableSparkVersionsUI":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/A%20Gentle%20Introduction%20to%20Apache%20Spark%20on%20Databricks.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/Quick%20Start%20DataFrames.html","displayName":"Quick Start DataFrames","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.cloud.databricks.com/docs/latest/featured_notebooks/GSW%20Passing%20Analysis%20(new).html","displayName":"GSW Passing Analysis (new)","icon":"img/home/Python_icon.svg"}],"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"enableTerminal":false,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"accounts":true,"useFramedStaticNotebooks":true,"enableNewProgressReportUI":true,"defaultCoresPerContainer":4,"showSqlProxyUI":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":4366652469169891,"name":"Python Tutorial","language":"python","commands":[{"version":"CommandV1","origId":4366652469169893,"guid":"98b6aa3d-5721-40e2-9c15-fc8fbd5815c3","subtype":"command","commandType":"auto","position":1.0,"command":"# Python lesson \n# https://learnxinyminutes.com/docs/python/\n\n# Single line comments start with a number symbol.\n\n\"\"\" Multiline strings can be written\n    using three \"s, and are often used\n    as comments\n\"\"\"\n\n\n####################################################\n## 1. Primitive Datatypes and Operators\n####################################################\n\n# You have numbers\n3  # => 3\n\n# Math is what you would expect\n1 + 1  # => 2\n8 - 1  # => 7\n10 * 2  # => 20\n35 / 5  # => 7\n\n# Division is a bit tricky. It is integer division and floors the results\n# automatically.\n5 / 2  # => 2\n\n# To fix division we need to learn about floats.\n2.0     # This is a float\n11.0 / 4.0  # => 2.75 ahhh...much better\n\n# Result of integer division truncated down both for positive and negative.\n5 // 3     # => 1\n5.0 // 3.0 # => 1.0 # works on floats too\n-5 // 3  # => -2\n-5.0 // 3.0 # => -2.0\n\n# Note that we can also import division module(Section 6 Modules)\n# to carry out normal division with just one '/'.\nfrom __future__ import division\n11/4    # => 2.75  ...normal division\n11//4   # => 2 ...floored division\n\n# Modulo operation\n7 % 3 # => 1\n\n# Exponentiation (x to the yth power)\n2**4 # => 16\n\n# Enforce precedence with parentheses\n(1 + 3) * 2  # => 8\n\n# Boolean Operators\n# Note \"and\" and \"or\" are case-sensitive\nTrue and False #=> False\nFalse or True #=> True\n\n# Note using Bool operators with ints\n0 and 2 #=> 0\n-5 or 0 #=> -5\n0 == False #=> True\n2 == True #=> False\n1 == True #=> True\n\n# negate with not\nnot True  # => False\nnot False  # => True\n\n# Equality is ==\n1 == 1  # => True\n2 == 1  # => False\n\n# Inequality is !=\n1 != 1  # => False\n2 != 1  # => True\n\n# More comparisons\n1 < 10  # => True\n1 > 10  # => False\n2 <= 2  # => True\n2 >= 2  # => True\n\n# Comparisons can be chained!\n1 < 2 < 3  # => True\n2 < 3 < 2  # => False\n\n# Strings are created with \" or '\n\"This is a string.\"\n'This is also a string.'\n\n# Strings can be added too!\n\"Hello \" + \"world!\"  # => \"Hello world!\"\n# Strings can be added without using '+'\n\"Hello \" \"world!\"  # => \"Hello world!\"\n\n# ... or multiplied\n\"Hello\" * 3  # => \"HelloHelloHello\"\n\n# A string can be treated like a list of characters\n\"This is a string\"[0]  # => 'T'\n\n# You can find the length of a string\nlen(\"This is a string\")  # => 16\n\n#String formatting with %\n#Even though the % string operator will be deprecated on Python 3.1 and removed\n#later at some time, it may still be good to know how it works.\nx = 'apple'\ny = 'lemon'\nz = \"The items in the basket are %s and %s\" % (x,y)\n\n# A newer way to format strings is the format method.\n# This method is the preferred way\n\"{} is a {}\".format(\"This\", \"placeholder\")\n\"{0} can be {1}\".format(\"strings\", \"formatted\")\n# You can use keywords if you don't want to count.\n\"{name} wants to eat {food}\".format(name=\"Bob\", food=\"lasagna\")\n\n# None is an object\nNone  # => None\n\n# Don't use the equality \"==\" symbol to compare objects to None\n# Use \"is\" instead\n\"etc\" is None  # => False\nNone is None  # => True\n\n# The 'is' operator tests for object identity. This isn't\n# very useful when dealing with primitive values, but is\n# very useful when dealing with objects.\n\n# Any object can be used in a Boolean context.\n# The following values are considered falsey:\n#    - None\n#    - zero of any numeric type (e.g., 0, 0L, 0.0, 0j)\n#    - empty sequences (e.g., '', (), [])\n#    - empty containers (e.g., {}, set())\n#    - instances of user-defined classes meeting certain conditions\n#      see: https://docs.python.org/2/reference/datamodel.html#object.__nonzero__\n#\n# All other values are truthy (using the bool() function on them returns True).\nbool(0)  # => False\nbool(\"\")  # => False\n\n\n####################################################\n## 2. Variables and Collections\n####################################################\n\n# Python has a print statement\nprint \"I'm Python. Nice to meet you!\" # => I'm Python. Nice to meet you!\n\n# Simple way to get input data from console\ninput_string_var = raw_input(\"Enter some data: \") # Returns the data as a string\ninput_var = input(\"Enter some data: \") # Evaluates the data as python code\n# Warning: Caution is recommended for input() method usage\n# Note: In python 3, input() is deprecated and raw_input() is renamed to input()\n\n# No need to declare variables before assigning to them.\nsome_var = 5    # Convention is to use lower_case_with_underscores\nsome_var  # => 5\n\n# Accessing a previously unassigned variable is an exception.\n# See Control Flow to learn more about exception handling.\nsome_other_var  # Raises a name error\n\n# if can be used as an expression\n# Equivalent of C's '?:' ternary operator\n\"yahoo!\" if 3 > 2 else 2  # => \"yahoo!\"\n\n\n# Lists store sequences\nli = []\n# You can start with a prefilled list\nother_li = [4, 5, 6]\n\n# Add stuff to the end of a list with append\nli.append(1)    # li is now [1]\nli.append(2)    # li is now [1, 2]\nli.append(4)    # li is now [1, 2, 4]\nli.append(3)    # li is now [1, 2, 4, 3]\n# Remove from the end with pop\nli.pop()        # => 3 and li is now [1, 2, 4]\n# Let's put it back\nli.append(3)    # li is now [1, 2, 4, 3] again.\n\n# Access a list like you would any array\nli[0]  # => 1\n# Assign new values to indexes that have already been initialized with =\nli[0] = 42\nli[0]  # => 42\nli[0] = 1  # Note: setting it back to the original value\n# Look at the last element\nli[-1]  # => 3\n\n# Looking out of bounds is an IndexError\nli[4]  # Raises an IndexError\n\n# You can look at ranges with slice syntax.\n# (It's a closed/open range for you mathy types.)\nli[1:3]  # => [2, 4]\n# Omit the beginning\nli[2:]  # => [4, 3]\n# Omit the end\nli[:3]  # => [1, 2, 4]\n# Select every second entry\nli[::2]   # =>[1, 4]\n# Reverse a copy of the list\nli[::-1]   # => [3, 4, 2, 1]\n# Use any combination of these to make advanced slices\n# li[start:end:step]\n\n# Remove arbitrary elements from a list with \"del\"\ndel li[2]   # li is now [1, 2, 3]\n\n# You can add lists\nli + other_li   # => [1, 2, 3, 4, 5, 6]\n# Note: values for li and for other_li are not modified.\n\n# Concatenate lists with \"extend()\"\nli.extend(other_li)   # Now li is [1, 2, 3, 4, 5, 6]\n\n# Remove first occurrence of a value\nli.remove(2)  # li is now [1, 3, 4, 5, 6]\nli.remove(2)  # Raises a ValueError as 2 is not in the list\n\n# Insert an element at a specific index\nli.insert(1, 2)  # li is now [1, 2, 3, 4, 5, 6] again\n\n# Get the index of the first item found\nli.index(2)  # => 1\nli.index(7)  # Raises a ValueError as 7 is not in the list\n\n# Check for existence in a list with \"in\"\n1 in li   # => True\n\n# Examine the length with \"len()\"\nlen(li)   # => 6\n\n\n# Tuples are like lists but are immutable.\ntup = (1, 2, 3)\ntup[0]   # => 1\ntup[0] = 3  # Raises a TypeError\n\n# You can do all those list thingies on tuples too\nlen(tup)   # => 3\ntup + (4, 5, 6)   # => (1, 2, 3, 4, 5, 6)\ntup[:2]   # => (1, 2)\n2 in tup   # => True\n\n# You can unpack tuples (or lists) into variables\na, b, c = (1, 2, 3)     # a is now 1, b is now 2 and c is now 3\nd, e, f = 4, 5, 6       # you can leave out the parentheses\n# Tuples are created by default if you leave out the parentheses\ng = 4, 5, 6             # => (4, 5, 6)\n# Now look how easy it is to swap two values\ne, d = d, e     # d is now 5 and e is now 4\n\n\n# Dictionaries store mappings\nempty_dict = {}\n# Here is a prefilled dictionary\nfilled_dict = {\"one\": 1, \"two\": 2, \"three\": 3}\n\n# Look up values with []\nfilled_dict[\"one\"]   # => 1\n\n# Get all keys as a list with \"keys()\"\nfilled_dict.keys()   # => [\"three\", \"two\", \"one\"]\n# Note - Dictionary key ordering is not guaranteed.\n# Your results might not match this exactly.\n\n# Get all values as a list with \"values()\"\nfilled_dict.values()   # => [3, 2, 1]\n# Note - Same as above regarding key ordering.\n\n# Get all key-value pairs as a list of tuples with \"items()\"\nfilled_dicts.items()    # => [(\"one\", 1), (\"two\", 2), (\"three\", 3)]\n\n# Check for existence of keys in a dictionary with \"in\"\n\"one\" in filled_dict   # => True\n1 in filled_dict   # => False\n\n# Looking up a non-existing key is a KeyError\nfilled_dict[\"four\"]   # KeyError\n\n# Use \"get()\" method to avoid the KeyError\nfilled_dict.get(\"one\")   # => 1\nfilled_dict.get(\"four\")   # => None\n# The get method supports a default argument when the value is missing\nfilled_dict.get(\"one\", 4)   # => 1\nfilled_dict.get(\"four\", 4)   # => 4\n# note that filled_dict.get(\"four\") is still => None\n# (get doesn't set the value in the dictionary)\n\n# set the value of a key with a syntax similar to lists\nfilled_dict[\"four\"] = 4  # now, filled_dict[\"four\"] => 4\n\n# \"setdefault()\" inserts into a dictionary only if the given key isn't present\nfilled_dict.setdefault(\"five\", 5)  # filled_dict[\"five\"] is set to 5\nfilled_dict.setdefault(\"five\", 6)  # filled_dict[\"five\"] is still 5\n\n\n# Sets store ... well sets (which are like lists but can contain no duplicates)\nempty_set = set()\n# Initialize a \"set()\" with a bunch of values\nsome_set = set([1, 2, 2, 3, 4])   # some_set is now set([1, 2, 3, 4])\n\n# order is not guaranteed, even though it may sometimes look sorted\nanother_set = set([4, 3, 2, 2, 1])  # another_set is now set([1, 2, 3, 4])\n\n# Since Python 2.7, {} can be used to declare a set\nfilled_set = {1, 2, 2, 3, 4}   # => {1, 2, 3, 4}\n\n# Add more items to a set\nfilled_set.add(5)   # filled_set is now {1, 2, 3, 4, 5}\n\n# Do set intersection with &\nother_set = {3, 4, 5, 6}\nfilled_set & other_set   # => {3, 4, 5}\n\n# Do set union with |\nfilled_set | other_set   # => {1, 2, 3, 4, 5, 6}\n\n# Do set difference with -\n{1, 2, 3, 4} - {2, 3, 5}   # => {1, 4}\n\n# Do set symmetric difference with ^\n{1, 2, 3, 4} ^ {2, 3, 5}  # => {1, 4, 5}\n\n# Check if set on the left is a superset of set on the right\n{1, 2} >= {1, 2, 3} # => False\n\n# Check if set on the left is a subset of set on the right\n{1, 2} <= {1, 2, 3} # => True\n\n# Check for existence in a set with in\n2 in filled_set   # => True\n10 in filled_set   # => False\n\n\n####################################################\n## 3. Control Flow\n####################################################\n\n# Let's just make a variable\nsome_var = 5\n\n# Here is an if statement. Indentation is significant in python!\n# prints \"some_var is smaller than 10\"\nif some_var > 10:\n    print \"some_var is totally bigger than 10.\"\nelif some_var < 10:    # This elif clause is optional.\n    print \"some_var is smaller than 10.\"\nelse:           # This is optional too.\n    print \"some_var is indeed 10.\"\n\n\n\"\"\"\nFor loops iterate over lists\nprints:\n    dog is a mammal\n    cat is a mammal\n    mouse is a mammal\n\"\"\"\nfor animal in [\"dog\", \"cat\", \"mouse\"]:\n    # You can use {0} to interpolate formatted strings. (See above.)\n    print \"{0} is a mammal\".format(animal)\n\n\"\"\"\n\"range(number)\" returns a list of numbers\nfrom zero to the given number\nprints:\n    0\n    1\n    2\n    3\n\"\"\"\nfor i in range(4):\n    print i\n\n\"\"\"\n\"range(lower, upper)\" returns a list of numbers\nfrom the lower number to the upper number\nprints:\n    4\n    5\n    6\n    7\n\"\"\"\nfor i in range(4, 8):\n    print i\n\n\"\"\"\nWhile loops go until a condition is no longer met.\nprints:\n    0\n    1\n    2\n    3\n\"\"\"\nx = 0\nwhile x < 4:\n    print x\n    x += 1  # Shorthand for x = x + 1\n\n# Handle exceptions with a try/except block\n\n# Works on Python 2.6 and up:\ntry:\n    # Use \"raise\" to raise an error\n    raise IndexError(\"This is an index error\")\nexcept IndexError as e:\n    pass    # Pass is just a no-op. Usually you would do recovery here.\nexcept (TypeError, NameError):\n    pass    # Multiple exceptions can be handled together, if required.\nelse:   # Optional clause to the try/except block. Must follow all except blocks\n    print \"All good!\"   # Runs only if the code in try raises no exceptions\nfinally: #  Execute under all circumstances\n    print \"We can clean up resources here\"\n\n# Instead of try/finally to cleanup resources you can use a with statement\nwith open(\"myfile.txt\") as f:\n    for line in f:\n        print line\n\n\n####################################################\n## 4. Functions\n####################################################\n\n# Use \"def\" to create new functions\ndef add(x, y):\n    print \"x is {0} and y is {1}\".format(x, y)\n    return x + y    # Return values with a return statement\n\n# Calling functions with parameters\nadd(5, 6)   # => prints out \"x is 5 and y is 6\" and returns 11\n\n# Another way to call functions is with keyword arguments\nadd(y=6, x=5)   # Keyword arguments can arrive in any order.\n\n\n# You can define functions that take a variable number of\n# positional args, which will be interpreted as a tuple by using *\ndef varargs(*args):\n    return args\n\nvarargs(1, 2, 3)   # => (1, 2, 3)\n\n# You can define functions that take a variable number of\n# keyword args, as well, which will be interpreted as a dict by using **\ndef keyword_args(**kwargs):\n    return kwargs\n\n# Let's call it to see what happens\nkeyword_args(big=\"foot\", loch=\"ness\")   # => {\"big\": \"foot\", \"loch\": \"ness\"}\n\n\n# You can do both at once, if you like\ndef all_the_args(*args, **kwargs):\n    print args\n    print kwargs\n\"\"\"\nall_the_args(1, 2, a=3, b=4) prints:\n    (1, 2)\n    {\"a\": 3, \"b\": 4}\n\"\"\"\n\n# When calling functions, you can do the opposite of args/kwargs!\n# Use * to expand positional args and use ** to expand keyword args.\nargs = (1, 2, 3, 4)\nkwargs = {\"a\": 3, \"b\": 4}\nall_the_args(*args)   # equivalent to foo(1, 2, 3, 4)\nall_the_args(**kwargs)   # equivalent to foo(a=3, b=4)\nall_the_args(*args, **kwargs)   # equivalent to foo(1, 2, 3, 4, a=3, b=4)\n\n# you can pass args and kwargs along to other functions that take args/kwargs\n# by expanding them with * and ** respectively\ndef pass_all_the_args(*args, **kwargs):\n    all_the_args(*args, **kwargs)\n    print varargs(*args)\n    print keyword_args(**kwargs)\n\n# Function Scope\nx = 5\n\ndef set_x(num):\n    # Local var x not the same as global variable x\n    x = num # => 43\n    print x # => 43\n\ndef set_global_x(num):\n    global x\n    print x # => 5\n    x = num # global var x is now set to 6\n    print x # => 6\n\nset_x(43)\nset_global_x(6)\n\n# Python has first class functions\ndef create_adder(x):\n    def adder(y):\n        return x + y\n    return adder\n\nadd_10 = create_adder(10)\nadd_10(3)   # => 13\n\n# There are also anonymous functions\n(lambda x: x > 2)(3)   # => True\n(lambda x, y: x ** 2 + y ** 2)(2, 1) # => 5\n\n# There are built-in higher order functions\nmap(add_10, [1, 2, 3])   # => [11, 12, 13]\nmap(max, [1, 2, 3], [4, 2, 1])   # => [4, 2, 3]\n\nfilter(lambda x: x > 5, [3, 4, 5, 6, 7])   # => [6, 7]\n\n# We can use list comprehensions for nice maps and filters\n[add_10(i) for i in [1, 2, 3]]  # => [11, 12, 13]\n[x for x in [3, 4, 5, 6, 7] if x > 5]   # => [6, 7]\n\n# You can construct set and dict comprehensions as well.\n{x for x in 'abcddeef' if x in 'abc'}  # => {'d', 'e', 'f'}\n{x: x**2 for x in range(5)}  # => {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}\n\n\n####################################################\n## 5. Classes\n####################################################\n\n# We subclass from object to get a class.\nclass Human(object):\n\n    # A class attribute. It is shared by all instances of this class\n    species = \"H. sapiens\"\n\n    # Basic initializer, this is called when this class is instantiated.\n    # Note that the double leading and trailing underscores denote objects\n    # or attributes that are used by python but that live in user-controlled\n    # namespaces. You should not invent such names on your own.\n    def __init__(self, name):\n        # Assign the argument to the instance's name attribute\n        self.name = name\n\n        # Initialize property\n        self.age = 0\n\n\n    # An instance method. All methods take \"self\" as the first argument\n    def say(self, msg):\n        return \"{0}: {1}\".format(self.name, msg)\n\n    # A class method is shared among all instances\n    # They are called with the calling class as the first argument\n    @classmethod\n    def get_species(cls):\n        return cls.species\n\n    # A static method is called without a class or instance reference\n    @staticmethod\n    def grunt():\n        return \"*grunt*\"\n\n    # A property is just like a getter.\n    # It turns the method age() into an read-only attribute\n    # of the same name.\n    @property\n    def age(self):\n        return self._age\n\n    # This allows the property to be set\n    @age.setter\n    def age(self, age):\n        self._age = age\n\n    # This allows the property to be deleted\n    @age.deleter\n    def age(self):\n        del self._age\n\n\n# Instantiate a class\ni = Human(name=\"Ian\")\nprint i.say(\"hi\")     # prints out \"Ian: hi\"\n\nj = Human(\"Joel\")\nprint j.say(\"hello\")  # prints out \"Joel: hello\"\n\n# Call our class method\ni.get_species()   # => \"H. sapiens\"\n\n# Change the shared attribute\nHuman.species = \"H. neanderthalensis\"\ni.get_species()   # => \"H. neanderthalensis\"\nj.get_species()   # => \"H. neanderthalensis\"\n\n# Call the static method\nHuman.grunt()   # => \"*grunt*\"\n\n# Update the property\ni.age = 42\n\n# Get the property\ni.age # => 42\n\n# Delete the property\ndel i.age\ni.age  # => raises an AttributeError\n\n\n####################################################\n## 6. Modules\n####################################################\n\n# You can import modules\nimport math\nprint math.sqrt(16)  # => 4\n\n# You can get specific functions from a module\nfrom math import ceil, floor\nprint ceil(3.7)  # => 4.0\nprint floor(3.7)   # => 3.0\n\n# You can import all functions from a module.\n# Warning: this is not recommended\nfrom math import *\n\n# You can shorten module names\nimport math as m\nmath.sqrt(16) == m.sqrt(16)   # => True\n# you can also test that the functions are equivalent\nfrom math import sqrt\nmath.sqrt == m.sqrt == sqrt  # => True\n\n# Python modules are just ordinary python files. You\n# can write your own, and import them. The name of the\n# module is the same as the name of the file.\n\n# You can find out which functions and attributes\n# defines a module.\nimport math\ndir(math)\n\n# If you have a Python script named math.py in the same\n# folder as your current script, the file math.py will\n# be loaded instead of the built-in Python module.\n# This happens because the local folder has priority\n# over Python's built-in libraries.\n\n\n####################################################\n## 7. Advanced\n####################################################\n\n# Generators\n# A generator \"generates\" values as they are requested instead of storing\n# everything up front\n\n# The following method (*NOT* a generator) will double all values and store it\n# in `double_arr`. For large size of iterables, that might get huge!\ndef double_numbers(iterable):\n    double_arr = []\n    for i in iterable:\n        double_arr.append(i + i)\n\n# Running the following would mean we'll double all values first and return all\n# of them back to be checked by our condition\nfor value in double_numbers(range(1000000)):  # `test_non_generator`\n    print value\n    if value > 5:\n        break\n\n# We could instead use a generator to \"generate\" the doubled value as the item\n# is being requested\ndef double_numbers_generator(iterable):\n    for i in iterable:\n        yield i + i\n\n# Running the same code as before, but with a generator, now allows us to iterate\n# over the values and doubling them one by one as they are being consumed by\n# our logic. Hence as soon as we see a value > 5, we break out of the\n# loop and don't need to double most of the values sent in (MUCH FASTER!)\nfor value in double_numbers_generator(xrange(1000000)):  # `test_generator`\n    print value\n    if value > 5:\n        break\n\n# BTW: did you notice the use of `range` in `test_non_generator` and `xrange` in `test_generator`?\n# Just as `double_numbers_generator` is the generator version of `double_numbers`\n# We have `xrange` as the generator version of `range`\n# `range` would return back and array with 1000000 values for us to use\n# `xrange` would generate 1000000 values for us as we request / iterate over those items\n\n# Just as you can create a list comprehension, you can create generator\n# comprehensions as well.\nvalues = (-x for x in [1,2,3,4,5])\nfor x in values:\n    print(x)  # prints -1 -2 -3 -4 -5 to console/terminal\n\n# You can also cast a generator comprehension directly to a list.\nvalues = (-x for x in [1,2,3,4,5])\ngen_to_list = list(values)\nprint(gen_to_list)  # => [-1, -2, -3, -4, -5]\n\n\n# Decorators\n# in this example beg wraps say\n# Beg will call say. If say_please is True then it will change the returned\n# message\nfrom functools import wraps\n\ndef beg(target_function):\n    @wraps(target_function)\n    def wrapper(*args, **kwargs):\n        msg, say_please = target_function(*args, **kwargs)\n        if say_please:\n            return \"{} {}\".format(msg, \"Please! I am poor :(\")\n        return msg\n\n    return wrapper\n\n@beg\ndef say(say_please=False):\n    msg = \"Can you buy me a beer?\"\n    return msg, say_please\n\nprint say()  # Can you buy me a beer?\nprint say(say_please=True)  # Can you buy me a beer? Please! I am poor :(\n","commandVersion":0,"state":"error","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0.0,"submitTime":0.0,"finishTime":0.0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c4be9167-7584-4a6d-9541-0b05dabb0dee"}],"dashboards":[],"guid":"2687723f-ff76-40a3-a6b8-89cefe6702e0","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
